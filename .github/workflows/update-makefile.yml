name: Conditional Makefile rebuild

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main


jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        if: github.event_name != 'pull_request'
        uses: actions/checkout@v3
        with:
          fetch-depth: 0

      - name: Checkout repository (PR)
        if: github.event_name == 'pull_request'
        uses: actions/checkout@v3
        with:
          fetch-depth: 0
          ref: ${{ github.head_ref }}

      - uses: nrwl/nx-set-shas@v3
        id: last_successful_commit
        # if: github.event_name != 'pull_request'
        with:
          main-branch-name: 'main'
          workflow-id: 'update-makefile.yml'

      - name: Check for changes in PKGBUILD folders
        id: check_assets
        run: |
          commit_message=$(git log -1 --pretty=%B)
          if [[ $commit_message =~ "\#NoRebuild" ]]; then
            echo "Skipping PKGBUILDs check due to #NoRebuild or [No Rebuild] in commit message"
            echo "has_PKGBUILD_changes=false" >> $GITHUB_OUTPUT
            echo "has_AUR_lock_changes=false" >> $GITHUB_OUTPUT
            exit 0
          fi

          github_event_name=$(echo $GITHUB_EVENT_NAME | tr '[:upper:]' '[:lower:]') 
          # if [ $github_event_name = "pull_request" ] ; then 
          #   base_commit="main"
          # else 
            base_commit="${{ steps.last_successful_commit.outputs.base }}"
          # fi 
          echo "base_commit=$base_commit"

          git diff --name-only "${base_commit}..HEAD" -- 'PKGBUILDs/*/PKGBUILD' 'PKGBUILDs-extra/*/PKGBUILD' > /tmp/changed_PKGBUILDs.txt
          if grep -qE 'PKGBUILDs/|PKGBUILDs-extra/' /tmp/changed_PKGBUILDs.txt; then
            echo "PKGBUILDs changed. .SCRINFO will be updated in the matrix task..."
            pkgbuilds=()
            while IFS= read -r file; do
              pkgbuilds+=("$file")
              echo "Changed: $file"
            done < /tmp/changed_PKGBUILDs.txt
            echo "has_PKGBUILD_changes=true"
            echo "has_PKGBUILD_changes=true" >> $GITHUB_OUTPUT
            json=$(echo "${pkgbuilds[@]}" | jq -R . | jq --indent 0 -s .) # encode array as json
            echo "pkgbuilds=$json"
            echo "pkgbuilds=$json" >> $GITHUB_OUTPUT
          fi
          if git diff --name-only "${base_commit}..HEAD" -- aur.lock | grep -q 'aur.lock'; then
            echo "aur.lock changed."
            make aur-lock
            echo "has_AUR_lock_changes=true" >> $GITHUB_OUTPUT
          fi

      - name: Set up Docker Buildx
        if: steps.check_assets.outputs.has_PKGBUILD_changes == 'true' || steps.check_assets.outputs.has_AUR_lock_changes == 'true'
        uses: docker/setup-buildx-action@v2

      - name: Build Docker image (or load from cache)
        if: steps.check_assets.outputs.has_PKGBUILD_changes == 'true' || steps.check_assets.outputs.has_AUR_lock_changes == 'true'
        uses: docker/build-push-action@v4
        with:
          context: ./.github/actions/makepkg
          file: ./.github/actions/makepkg/Dockerfile
          push: false
          tags: gha-makepkg-x86_64:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          load: true

      # - name: Check for changes in Makefile
      #   if: steps.check_assets.outputs.has_PKGBUILD_changes == 'true' || steps.check_assets.outputs.has_AUR_lock_changes == 'true'
      #   uses: ./.github/actions/makepkg
      #   with:
      #     operation: makefile-update
      #     packages: ${{ steps.check_assets.outputs.pkgbuilds }}
      #     rebuildall: false
      - name: "Check for changes in Makefile"
        if: steps.check_assets.outputs.has_PKGBUILD_changes == 'true' || steps.check_assets.outputs.has_AUR_lock_changes == 'true'
        run: | 
          docker run --rm  -v $PWD:/build -e INPUT_OPERATION=makefile-update -e INPUT_PACKAGES='${{ steps.check_assets.outputs.pkgbuilds }}' gha-makepkg-x86_64:latest

      - name: Rebuild Makefile
        if: steps.check_assets.outputs.has_PKGBUILD_changes == 'true' || steps.check_assets.outputs.has_AUR_lock_changes == 'true'
        id: rebuild_makefile
        run: ./tools/generate-makefile.ps1 -SkipSrcInfoCheck
        shell: pwsh

      - name: Commit changes
        id: commit_changes
        if: steps.check_assets.outputs.has_PKGBUILD_changes == 'true' || steps.check_assets.outputs.has_AUR_lock_changes == 'true'
        run: |
          git config --local user.email "ovos-arch-buildbot@noemail.local"
          git config --local user.name "OVOS Arch BuildBot"
          git add .
          git diff-index --quiet HEAD || git commit -m "Update Makefile"
          git push

          # Update the last successful commit hash
          echo "current_commit=$(git rev-parse HEAD)" >> $GITHUB_OUTPUT
          echo "current_commit=$(git rev-parse HEAD)"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

    outputs:
      has_PKGBUILD_changes: ${{ steps.check_assets.outputs.has_PKGBUILD_changes }}
      has_AUR_lock_changes: ${{ steps.check_assets.outputs.has_AUR_lock_changes }}
      pkgbuilds: ${{ steps.check_assets.outputs.pkgbuilds }}
      commit_hash: ${{ steps.commit_changes.outputs.current_commit }}

  # Because running QEMU builds on GitHub Actions is slow as molasses AND because the project's
  # python packages are predominantly built for the `any` architecture, we will first build
  # the x86_64 target and then distribute any `any` packages to the other architectures. 
  # This stage will filter out `any` packages and will pass down native packages to the next stage(s)
  package-build-amd64:
    needs: check
    if: needs.check.outputs.has_PKGBUILD_changes == 'true'
    runs-on: ubuntu-latest
    name: Build `x86_64` native and `any` arch packages
    steps:
    - name: "Checkout repository"
      uses: actions/checkout@v3
      with:
        fetch-depth: 1
        ref: ${{ needs.check.outputs.commit_hash }}
    - name: "Download repo from Azure Blob Storage"
      if: false
      run: |
        echo "Downloading repo DB..."
        mkdir -p .repo/{x86_64,aarch64}        
        wget https://ovosarchlinuxpkgs.blob.core.windows.net/ovos-arch/x86_64/ovos-arch.db.tar.gz -O .repo/x86_64/ovos-arch.db.tar.gz
        wget https://ovosarchlinuxpkgs.blob.core.windows.net/ovos-arch/aarch64/ovos-arch.db.tar.gz -O .repo/aarch64/ovos-arch.db.tar.gz
        # cp .repo/x86_64/ovos-arch.db.tar.gz .repo/x86_64/ovos-arch.db.tar.gz.bak
        # cp .repo/aarch64/ovos-arch.db.tar.gz .repo/aarch64/ovos-arch.db.tar.gz.bak
    # Restore the cache, if available
    - name: Restore Docker cache
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ hashFiles('**/Dockerfile') }}
        restore-keys: |
          ${{ runner.os }}-buildx-
    - name: "Build on x86_64"
      uses: ./.github/actions/makepkg
      with:
        operation: repo-build
        packages: ${{ needs.check.outputs.pkgbuilds }}
        rebuildall: false
        repourl: https://ovosarchlinuxpkgs.blob.core.windows.net/ovos-arch
    - name: "Preparing packages"
      id: identify_available_packages
      if: github.event_name != 'pull_request'
      run: |
        if ls .repo/x86_64/*.pkg.tar.* 1> /dev/null 2>&1 ; then
          echo "upload_x86_64=true"
          echo "upload_x86_64=true" >> $GITHUB_OUTPUT
        fi
        if ls .repo/aarch64/*.pkg.tar.* 1> /dev/null 2>&1 ; then
          echo "upload_aarch64=true"
          echo "upload_aarch64=true" >> $GITHUB_OUTPUT
        fi

    - name: "Upload x86_64 packages to Azure Blob Storage"
      if: steps.identify_available_packages.outputs.upload_x86_64 == 'true'
      uses: azure/CLI@v1
      with:
        azcliversion: 2.50.0
        inlineScript: |
          az storage blob upload-batch --account-name ovosarchlinuxpkgs --destination ovos-arch --destination-path x86_64 --source .repo/x86_64 --pattern "ovos-arch.db*" --content-encoding "gzip" --overwrite  
          az storage blob upload-batch --account-name ovosarchlinuxpkgs --destination ovos-arch --destination-path x86_64 --source .repo/x86_64 --pattern "*.pkg.tar.*" --content-encoding "gzip" --overwrite 
      env:
        AZURE_STORAGE_KEY: "${{ secrets.AZURE_STORAGE_KEY }}"

    - name: "Upload aarch64 packages to Azure Blob Storage"
      if: steps.identify_available_packages.outputs.upload_aarch64 == 'true'
      uses: azure/CLI@v1
      with:
        azcliversion: 2.50.0
        inlineScript: |
          az storage blob upload-batch --account-name ovosarchlinuxpkgs --destination ovos-arch --destination-path aarch64 --source .repo/aarch64 --pattern "ovos-arch.db*" --content-encoding "gzip" --overwrite 
          az storage blob upload-batch --account-name ovosarchlinuxpkgs --destination ovos-arch --destination-path aarch64 --source .repo/aarch64 --pattern "*.pkg.tar.*" --content-encoding "gzip" --overwrite 
      env:
        AZURE_STORAGE_KEY: "${{ secrets.AZURE_STORAGE_KEY }}"

    # At this point the .repo/aarch64/ folder will possibly contain -any.pkg.tar.{zst,xz} files
    # We need to filter out the -any packages from the `needs.check.outputs.pkgbuilds` array
    # and pass down the native packages to the next stage. 
    # The pkgbuilds string contains entries in the format PKGBUILDs{,-extra}/<package_name>/PKGUILD 
    # encoded as a JSON array.
    # We iterate over -any.pkg.tar.{zst,xz} files extracting <package_name>, which ends before
    # the third dash counting from the end of the filename.
    - name: "Select native ARM packages to build"
      id: select_native_arm_packages
      run: |  
        native_pkgbuilds=()
        original_pkgbuilds=($(echo '${{ needs.check.outputs.pkgbuilds }}' | jq -r '.[]'))
        echo "original_pkgbuilds='${original_pkgbuilds[@]}'"
        cd .repo/aarch64/
        pkgfiles=( *-any.pkg.tar.* )
        if (( ${#pkgfiles[@]} )); then
          echo "pkgfiles='${pkgfiles[@]}'"
          for pkg in $pkgfiles ; do
            echo "pkg=$pkg"
            pkgname=$(echo $pkg | rev | cut -d'-' -f4- | rev)
            echo "pkgname=$pkgname"
            for entry in $original_pkgbuilds ; do
              echo "entry=$entry, pkgname=$pkgname"
              if [[ $entry == *"/$pkgname/"* ]]; then
                echo "$entry has already been built for ARM, skipping..."
              else
                native_pkgbuilds+=($entry)
              fi
            done
          done
        else
          echo "Did not find any package files..."
        fi
        echo "pkgbuilds=${native_pkgbuilds[@]}"
        echo "pkgbuilds=${native_pkgbuilds[@]}" >> $GITHUB_OUTPUT

    outputs:
      pkgbuilds: ${{ steps.select_native_arm_packages.outputs.pkgbuilds }}

  package-build-arm:
    needs: package-build-amd64
    if: false && needs.package-build-amd64.outputs.pkgbuilds != ''
    runs-on: ubuntu-latest
    name: Build ARM packages
    # strategy:
    #   matrix:
    #     arch: ['aarch64']
    steps:
    - name: "Checkout repository"
      uses: actions/checkout@v3
      with:
        fetch-depth: 1
        ref: ${{ needs.check.outputs.commit_hash }}

    - name: "Download repo from Azure Blob Storage"
      if: false
      run: |
        echo "Downloading repo DB..."
        mkdir -p .repo/aarch64        
        wget https://ovosarchlinuxpkgs.blob.core.windows.net/ovos-arch/aarch64/ovos-arch.db.tar.gz -O .repo/aarch64/ovos-arch.db.tar.gz
        # cp .repo/aarch64/ovos-arch.db.tar.gz .repo/aarch64/ovos-arch.db.tar.gz.bak

    - name: Restore Docker cache
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ hashFiles('**/Dockerfile') }}
        restore-keys: |
          ${{ runner.os }}-buildx-

    - name: Set up QEMU
      uses: docker/setup-qemu-action@v2
      with:
        platforms: arm64

    - name: Check if base-devel image is cached
      id: check-cache
      run: |
        if docker image ls | grep -q 'archlinux-arm64v8 base-devel'; then
          echo "Cache hit for archlinux-arm64v8:base-devel"
          echo "cache-hit=true" >> $GITHUB_OUTPUT
        else
          echo "Cache miss for archlinux-arm64v8:base-devel"
          echo "cache-hit=false" >> $GITHUB_OUTPUT
        fi

    - name: Build base-devel image if not cached
      if: steps.check-cache.outputs.cache-hit != 'true'
      run: |
        wget http://os.archlinuxarm.org/os/ArchLinuxARM-aarch64-latest.tar.gz
        gzip -d ArchLinuxARM-aarch64-latest.tar.gz
        docker import ArchLinuxARM-aarch64-latest.tar archlinux-arm64v8:latest
        docker build -t archlinux-arm64v8:base-devel -f ./tools/container-build/base-devel/Containerfile ./tools/container-build/base-devel
        docker image rm archlinux-arm64v8:latest

    - name: Build Docker image
      run: |
        docker build --build-arg ARCH="-arm64v8" -t gha-makepkg-arm64v8 ./.github/actions/makepkg

    - name: Save Docker cache
      uses: actions/cache@v3
      with:
        path: /tmp/.buildx-cache
        key: ${{ runner.os }}-buildx-${{ hashFiles('**/Dockerfile') }}
          
    - name: "Build on aarch64"
      run: | 
        docker run --rm -v $PWD:/build -e INPUT_OPERATION=repo-build -e INPUT_PACKAGES='${{ needs.check.outputs.pkgbuilds }}' -e INPUT_REPOURL=https://ovosarchlinuxpkgs.blob.core.windows.net/ovos-arch gha-makepkg-arm64v8

    - name: "Preparing native aarch64 packages"
      id: identify_available_packages
      if: github.event_name != 'pull_request'
      run: |
        if ls .repo/aarch64/*.pkg.tar.* 1> /dev/null 2>&1 ; then
          echo "upload_aarch64=true"
          echo "upload_aarch64=true" >> $GITHUB_OUTPUT
        fi

    - name: "Upload aarch64 native packages to Azure Blob Storage"
      if: steps.identify_available_packages.outputs.upload_aarch64 == 'true'
      uses: azure/CLI@v1
      with:
        azcliversion: 2.50.0
        inlineScript: |
          az storage blob upload-batch --account-name ovosarchlinuxpkgs --destination ovos-arch --destination-path aarch64 --source .repo/aarch64 --pattern "ovos-arch.db*" --content-encoding "gzip" --overwrite 
          az storage blob upload-batch --account-name ovosarchlinuxpkgs --destination ovos-arch --destination-path aarch64 --source .repo/aarch64 --pattern "*.pkg.tar.*" --content-encoding "gzip" --overwrite 
      env:
        AZURE_STORAGE_KEY: "${{ secrets.AZURE_STORAGE_KEY }}"